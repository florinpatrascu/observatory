receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318

  jaeger:
    protocols:
      grpc:
        endpoint: 0.0.0.0:14250
      thrift_http:
        endpoint: 0.0.0.0:14268

  zipkin:
    endpoint: 0.0.0.0:9411

processors:
  batch:
    send_batch_size: 1024
    timeout: 10s

  # ==================================================================================
  # OPTIONAL: Tail Sampling - Filter spans based on duration and other criteria
  # ==================================================================================
  # Tail sampling allows you to make sampling decisions AFTER knowing the full trace.
  # This is useful for filtering out fast/uninteresting spans while keeping errors
  # and slow operations.
  #
  # IMPORTANT NOTES:
  # 1. Introduces latency (decision_wait) - traces are buffered before export
  # 2. Uses memory to buffer traces - tune num_traces based on your traffic
  # 3. Filters ALL applications sending traces to this collector
  # 4. Root spans (HTTP requests) should always be sampled to maintain trace integrity
  #
  # HOW TO ENABLE:
  # 1. Uncomment the tail_sampling configuration below
  # 2. Add 'tail_sampling' to the processors list in service.pipelines.traces
  #    Example: processors: [tail_sampling, batch]
  # 3. Restart OTEL Collector: docker-compose restart otel-collector
  #
  # TUNING THRESHOLDS:
  # - threshold_ms: 0.1   = 100 microseconds (very aggressive filtering)
  # - threshold_ms: 0.5   = 500 microseconds (filter fast system queries)
  # - threshold_ms: 1     = 1 millisecond (recommended starting point)
  # - threshold_ms: 5     = 5 milliseconds (only trace slow operations)
  # - threshold_ms: 10    = 10 milliseconds (only trace very slow operations)
  #
  # ==================================================================================

  # tail_sampling:
  #   # How long to wait before making sampling decision (allows all spans to arrive)
  #   decision_wait: 10s
  #   # Number of traces kept in memory (adjust based on traffic: ~50-100 traces/sec = 50000)
  #   num_traces: 50000
  #   # Expected number of new traces per second (helps with memory allocation)
  #   expected_new_traces_per_sec: 100
  #
  #   policies:
  #     # Policy 1: Always keep traces with errors
  #     - name: errors-policy
  #       type: status_code
  #       status_code:
  #         status_codes: [ERROR]
  #
  #     # Policy 2: Keep spans longer than threshold (adjust threshold_ms as needed)
  #     - name: slow-spans-policy
  #       type: latency
  #       latency:
  #         threshold_ms: 1  # 1ms = 1000Î¼s (adjust: 0.1, 0.5, 1, 5, 10, etc.)
  #
  #     # Policy 3: Always keep root spans (HTTP requests) to maintain trace structure
  #     # Note: This ensures you see all HTTP requests, even if child spans are filtered
  #     - name: root-spans-policy
  #       type: and
  #       and:
  #         and_sub_policy:
  #           - name: is-root
  #             type: span_count
  #             span_count:
  #               min_spans: 1

exporters:
  otlp:
    endpoint: tempo:4317
    tls:
      insecure: true

service:
  pipelines:
    traces:
      receivers: [otlp, jaeger, zipkin]
      processors: [batch] # Add 'tail_sampling' before 'batch' to enable span filtering
      exporters: [otlp]
